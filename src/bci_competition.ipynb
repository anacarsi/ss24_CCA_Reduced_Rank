{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BCI Competition III Dataset IV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Load training and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), \"..\", \"data\", \"bci_competition\")\n",
    "data_psd_path = os.path.join(data_path, \"data_psd\")\n",
    "\n",
    "# Channel indices for left and right brain\n",
    "left_channels = [0, 36, 60]  # C3, CP1, P3\n",
    "right_channels = [24, 48, 84]  # C4, CP2, P4\n",
    "\n",
    "\n",
    "def load_psd_file(file_path, include_labels=True):\n",
    "    \"\"\"\n",
    "    Load a PSD file and extract features and labels\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
    "    features = data.iloc[:, :96]\n",
    "    labels = data.iloc[:, 96] if include_labels else None\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Extract left and right regions (electrodes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 96 PSD features (12 frequency bands for 8 channels). We need to extract the left and right brain regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left channels: **[C3, CP1, CP5, P3]** → 4 channels → 4×12=48 features.\n",
    "Right channels: **[C4, CP2, CP6, P4]** → 4 channels → also 48 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_left_right_features(features):\n",
    "    \"\"\"\n",
    "    Extract left and right brain features from the PSD data.\n",
    "    \"\"\"\n",
    "    left_features = pd.concat(\n",
    "        [features.iloc[:, i : i + 12] for i in left_channels], axis=1\n",
    "    )  # skip each 12 columns\n",
    "    right_features = pd.concat(\n",
    "        [features.iloc[:, i : i + 12] for i in right_channels], axis=1\n",
    "    )\n",
    "    return left_features, right_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
      "C:\\Users\\anaca\\AppData\\Local\\Temp\\ipykernel_18220\\962179718.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "train_files = [f for f in os.listdir(data_psd_path) if f.startswith(\"train\")]\n",
    "train_data = {}\n",
    "for file in train_files:\n",
    "    file_path = os.path.join(data_psd_path, file)\n",
    "    features, labels = load_psd_file(file_path)\n",
    "    left_features, right_features = extract_left_right_features(features)\n",
    "    train_data[file] = (left_features, right_features, labels)\n",
    "\n",
    "train_left = pd.concat([data[0] for data in train_data.values()])\n",
    "train_right = pd.concat([data[1] for data in train_data.values()])\n",
    "train_labels = pd.concat([data[2] for data in train_data.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Resample to get predictions every 0.5 seconds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the competition, we need to average every 8 consecutive samples to predict the task every 0.5 seconds (since the sampling rate is 16 Hz, each 8 samples correspond to 0.5 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_features(features, step=8):\n",
    "    \"\"\"\n",
    "    Resample features by averaging over intervals of 0.5s.\n",
    "    \"\"\"\n",
    "    num_samples = len(features)\n",
    "    num_intervals = num_samples // step\n",
    "    resampled = np.mean(\n",
    "        features[: num_intervals * step].values.reshape(-1, step, features.shape[1]),\n",
    "        axis=1,\n",
    "    )\n",
    "    return pd.DataFrame(resampled)\n",
    "\n",
    "\n",
    "train_left_resampled = resample_features(train_left)\n",
    "train_right_resampled = resample_features(train_right)\n",
    "\n",
    "xt = train_left_resampled  # Left electrode features\n",
    "yt = train_right_resampled  # Right electrode features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Combine and prepare for the Adaptive CCA Alg.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**x_t**: (36-dimensional feature vector).\n",
    "**y_t**: (class labels) for each time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xt shape: (3902, 36)\n",
      "yt shape: (3902, 36)\n"
     ]
    }
   ],
   "source": [
    "print(\"xt shape:\", xt.shape)\n",
    "print(\"yt shape:\", yt.shape)\n",
    "np.save(\"xt.npy\", xt)\n",
    "np.save(\"yt.npy\", yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Adaptive CCA Implemented**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **A. Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xt = np.load(\"xt.npy\")  # left hemisphere features (n_samples, 36)\n",
    "yt = np.load(\"yt.npy\")  # right hemisphere features (n_samples, 36)\n",
    "\n",
    "# Preprocess (normalize)\n",
    "xt = (xt - np.mean(xt, axis=0)) / np.std(xt, axis=0)\n",
    "yt = (yt - np.mean(yt, axis=0)) / np.std(yt, axis=0)\n",
    "\n",
    "n_samples, nx = xt.shape\n",
    "_, ny = yt.shape\n",
    "p = 4  # Rank of decomposition (number of principal directions)\n",
    "beta = 0.98  # Forgetting factor, test with 0.99, 0.98, 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cx = np.eye(nx)\n",
    "Cy = np.eye(ny)\n",
    "Cxy = np.zeros((nx, ny))\n",
    "\n",
    "# Initialize subspaces\n",
    "Ux = np.random.randn(nx, p)  # Random init\n",
    "Vy = np.random.randn(ny, p)\n",
    "Ux, _ = np.linalg.qr(Ux)  # Orthonormalize Ux\n",
    "Vy, _ = np.linalg.qr(Vy)  # Orthonormalize Vy\n",
    "\n",
    "# Storage for residuals and reconstruction error\n",
    "reconstruction_errors = []\n",
    "detected_changes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **B. Computing the CCA model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of the algorithm based on suggested steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adap_cca(xt, yt, beta=0.98, p=4):\n",
    "    for t in range(n_samples):\n",
    "        # Get the current sample\n",
    "        x_t = xt[t].reshape(-1, 1)\n",
    "        y_t = yt[t].reshape(-1, 1)\n",
    "\n",
    "        # Update covariance matrices\n",
    "        Cx = beta * Cx + (1 - beta) * x_t @ x_t.T\n",
    "        Cy = beta * Cy + (1 - beta) * y_t @ y_t.T\n",
    "        Cxy = beta * Cxy + (1 - beta) * x_t @ y_t.T\n",
    "\n",
    "        # Compute generalized eigenvalue problem\n",
    "        Mx = np.linalg.inv(Cx) @ Cxy @ np.linalg.inv(Cy) @ Cxy.T\n",
    "        My = np.linalg.inv(Cy) @ Cxy.T @ np.linalg.inv(Cx) @ Cxy\n",
    "        eig_vals_x, eig_vecs_x = np.linalg.eigh(Mx)\n",
    "        eig_vals_y, eig_vecs_y = np.linalg.eigh(My)\n",
    "\n",
    "        # Take top p components\n",
    "        Ux = eig_vecs_x[:, -p:]\n",
    "        Vy = eig_vecs_y[:, -p:]\n",
    "\n",
    "        # Compute residuals\n",
    "        rx_t = np.linalg.inv(Cx) @ (np.eye(nx) - Ux @ Ux.T) @ x_t\n",
    "        ry_t = np.linalg.inv(Cy) @ (np.eye(ny) - Vy @ Vy.T) @ y_t\n",
    "\n",
    "        # Compute reconstruction error\n",
    "        c_t = 0.5 * (rx_t.T @ Cx @ rx_t / nx + ry_t.T @ Cy @ ry_t / ny)\n",
    "        reconstruction_errors.append(c_t.item())\n",
    "\n",
    "        # Detect changes (based on a threshold tau)\n",
    "        if len(reconstruction_errors) > 5:\n",
    "            if reconstruction_errors[-1] > np.percentile(reconstruction_errors[:t], 95):\n",
    "                if len(detected_changes) == 0 or (t - detected_changes[-1] > 5):\n",
    "                    detected_changes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(reconstruction_errors, label=\"Reconstruction Error\")\n",
    "for change in detected_changes:\n",
    "    plt.axvline(change, color=\"r\", linestyle=\"--\", label=\"Detected Change\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Reconstruction Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Reconstruction Error and Detected Changes\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate Performance\n",
    "# Assuming `true_changes` contains ground truth change points\n",
    "true_changes = []  # Populate with known change points\n",
    "y_true = np.zeros(n_samples)\n",
    "y_pred = np.zeros(n_samples)\n",
    "\n",
    "y_true[true_changes] = 1\n",
    "y_pred[detected_changes] = 1\n",
    "\n",
    "auc = roc_auc_score(y_true, reconstruction_errors) if true_changes else None\n",
    "if auc:\n",
    "    print(f\"AUC of Change Detection: {auc:.4f}\")\n",
    "else:\n",
    "    print(\"No ground truth change points provided.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cca_env_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
