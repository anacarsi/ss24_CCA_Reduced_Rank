{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (GSE48213): Identifying gene expression patterns associated with different breast cancer subtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes both treated (estrogen) and control conditions. \n",
    "We use Adaptive CCA to identify differences in gene expression patterns between these conditions over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time points (1, 2, 4, 8, 12 hours) are not equally spaced, which is common in biological experiments. \n",
    "- Adaptive CCA should handle such non-linear time progressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), \"..\", \"data\", \"GSE48213\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset overview:\n",
    "\n",
    "- 56 breast cancer cell lines were profiled\n",
    "- The data represents gene expression levels in these cell lines\n",
    "- Each cell line is in an unperturbed, baseline state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In current file: \n",
    "\n",
    "1. Column 1 (EnsEMBL_Gene_ID): unique identifier for each gene from the Ensembl database\n",
    "2. Column 2 (e.g., MDAMB453): expression value for each gene in the specific cell line.\n",
    "\n",
    "These are normalized read counts or FPKM/TPM values (Fragments/Transcripts Per Kilobase Million).\n",
    "Higher values indicate higher expression of the gene in that cell line, zero values indicate that the gene is not expressed (or expression is below detection threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_data\n",
    "load_data(file_path, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(os.getcwd(), \"combined_data.txt\")\n",
    "data = pd.read_csv(output_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing: Log2 Transformation\n",
    "Gene expression values vary too much across genes and cell lines, with some genes having very high expression values and others having very low ones (sometimes even zero). This creates a skewed distribution. A log2 transformation helps to normalize this range and make the data more comparable across genes and cell lines.\n",
    "- without log transformation, highly expressed genes dominate the analysis, hiding patterns in the data for moderately or lowly expressed genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREPROCESSING ----------  #\n",
    "from preprocessing import log2_transform, classify\n",
    "\n",
    "log2_data = log2_transform(data)\n",
    "# classify(log2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_distribution(log2_transformed_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the distribution of log2 transformed gene expression data.\n",
    "    \n",
    "    Arguments:\n",
    "    - log2_transformed_data: DataFrame with the log2 transformed gene expression values.\n",
    "    \"\"\"\n",
    "    # Exclude the gene ID column\n",
    "    expression_data = log2_transformed_data.iloc[:, 1:]\n",
    "    \n",
    "    # Histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(expression_data.values.flatten(), bins=50, kde=True, color='lightpink')\n",
    "    plt.title('Distribution of Log2 Transformed Gene Expression Values', fontweight='bold')\n",
    "    plt.xlabel('Log2 Expression Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot\n",
    "    cmap = plt.cm.Blues\n",
    "    colors = cmap(np.linspace(0.3, 1, 56))  # Generating shades of blue\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ax = sns.boxplot(data=data, palette=colors)\n",
    "    \n",
    "    plt.title(\"Boxplot of Breast Cancer Cell Line Gene Expression\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Cell Line\")\n",
    "    plt.ylabel(\"Gene Expression\")\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(log2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = pd.read_csv('cell_line_subtypes.csv', index_col=0)  # Genes x Cell lines\n",
    "# select rows for which column subtype is not \"Unclsasified\"\n",
    "subtypes = expression_data['Subtype']\n",
    "subtypes = subtypes[subtypes != 'Unclassified']\n",
    "expression_data = expression_data.loc[subtypes.index]\n",
    "print(expression_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all data employed, no enough cell lines can be classified, leading to poor data information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "import mygene\n",
    "\n",
    "def classify_genes_in_pathways():\n",
    "    \"\"\" \n",
    "    Find which genes are in which KEGG pathways.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv('combined_data.txt', sep='\\t', index_col=0)\n",
    "    genes = data.index.tolist()\n",
    "\n",
    "    # Convert Ensembl IDs to gene symbols\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    gene_info = mg.querymany(genes, scopes='ensembl.gene', fields='symbol', species='human')\n",
    "    ensembl_to_symbol = {gene['query']: gene.get('symbol', '') for gene in gene_info if 'symbol' in gene} # create a dictionary of Ensembl IDs to gene symbols\n",
    "\n",
    "    # Load KEGG pathway gene sets\n",
    "    kegg_gene_sets = gp.get_library('KEGG_2021_Human')\n",
    "    gene_pathway_map = {}\n",
    "\n",
    "    for pathway, pathway_genes in kegg_gene_sets.items():\n",
    "        # Find genes that are both in data and in the pathway\n",
    "        common_genes = set(ensembl_to_symbol.values()).intersection(pathway_genes)\n",
    "        \n",
    "        # If there are common genes, add them to the gene_pathway_map\n",
    "        for gene_symbol in common_genes:\n",
    "            ensembl_ids = [ensembl for ensembl, symbol in ensembl_to_symbol.items() if symbol == gene_symbol]\n",
    "            for ensembl_id in ensembl_ids:\n",
    "                if ensembl_id not in gene_pathway_map:\n",
    "                    gene_pathway_map[ensembl_id] = []\n",
    "                gene_pathway_map[ensembl_id].append(pathway)\n",
    "\n",
    "    # Create a DataFrame from the gene_pathway_map\n",
    "    result_df = pd.DataFrame.from_dict(gene_pathway_map, orient='index')\n",
    "    result_df.columns = [f'Pathway_{i+1}' for i in range(result_df.shape[1])]\n",
    "\n",
    "    result_df.to_csv('gene_pathway_mappings.csv')\n",
    "    \n",
    "    total_genes = len(genes)\n",
    "    mapped_genes = len(gene_pathway_map)\n",
    "    print(f\"Total genes in your data: {total_genes}\")\n",
    "    print(f\"Genes mapped to KEGG pathways: {mapped_genes}\")\n",
    "    print(f\"Percentage of genes mapped: {mapped_genes/total_genes*100:.2f}%\")\n",
    "\n",
    "    # Print the first few rows of the result\n",
    "    print(\"\\nFirst few gene-pathway mappings:\")\n",
    "    print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_genes_in_pathways()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pd.read_csv('combined_data.txt', sep='\\t', index_col=0)\n",
    "gene_pathway_mappings = pd.read_csv('gene_pathway_mappings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, Y = preprocessing(gene_expression, gene_pathway_mappings)\n",
    "\n",
    "# Ensure X and Y are centered and scaled\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = scaler.fit_transform(Y)\n",
    "\n",
    "# Set dimensions\n",
    "n, p1 = X.shape\n",
    "_, p2 = Y.shape\n",
    "k = min(p1, p2, 10)  # number of canonical dimensions, adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if X or Y have Nan values\n",
    "print(np.isnan(X).any())\n",
    "print(np.isnan(Y).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import cholesky, polar\n",
    "\n",
    "def cca_objective(X: np.ndarray, Y: np.ndarray, A: np.ndarray, B: np.ndarray) -> float:\n",
    "    \"\"\" \n",
    "    Compute the objective function for CCA.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        The first dataset (genes with expressions).\n",
    "    Y : np.ndarray\n",
    "        The second dataset (pathways of the genes).\n",
    "    A : np.ndarray\n",
    "        The first projection matrix.\n",
    "    B : np.ndarray\n",
    "        The second projection matrix.\n",
    "    \"\"\"\n",
    "    XA = X @ A\n",
    "    YB = Y @ B\n",
    "    corr = np.sum(XA * YB) / (n - 1)\n",
    "    return -corr  # negative because we're maximizing\n",
    "\n",
    "def cca_gradient(X: np.ndarray, Y: np.ndarray, A: np.ndarray, B: np.ndarray) -> tuple:\n",
    "    \"\"\" \n",
    "    Compute the gradient of the objective function for CCA.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        The first dataset (genes with expressions).\n",
    "    Y : np.ndarray  \n",
    "        The second dataset (pathways of the genes).\n",
    "    A : np.ndarray\n",
    "        The first projection matrix.\n",
    "    B : np.ndarray\n",
    "        The second projection matrix.\n",
    "    \"\"\"\n",
    "    assert X.shape[1] == A.shape[0] == B.shape[0]\n",
    "    assert Y.shape[1] == A.shape[1] == B.shape[1]\n",
    "    assert np.linalg.matrix_rank(A) == A.shape[1]\n",
    "    assert np.linalg.matrix_rank(B) == B.shape[1]\n",
    "    XA = X @ A\n",
    "    YB = Y @ B    \n",
    "    grad_A = -X.T @ YB / (n - 1)\n",
    "    grad_B = -Y.T @ XA / (n - 1)\n",
    "    return grad_A, grad_B\n",
    "\n",
    "def cholesky_qr_retraction(X: np.ndarray, G: np.ndarray, xi: np.ndarray, epsilon=1e-6) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Retract a point on the Stiefel manifold using the Cholesky QR retraction. Add regularization to avoid singular matrices.\n",
    "    \"\"\"\n",
    "    Z = (X + xi).T @ G @ (X + xi)\n",
    "    Z += epsilon * np.eye(Z.shape[0])  # Add regularization\n",
    "    try:\n",
    "        L = cholesky(Z, lower=True)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # If Cholesky fails, fall back to Polar decomposition\n",
    "        return polar_retraction(X, G, xi)\n",
    "    retracted_point = (X + xi) @ np.linalg.inv(L.T)\n",
    "    return retracted_point\n",
    "\n",
    "\n",
    "def polar_retraction(X: np.ndarray, G: np.ndarray, xi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Retract a point on the Stiefel manifold using the polar retraction.\n",
    "    \"\"\"\n",
    "    Z = (X + xi).T @ G @ (X + xi)\n",
    "    U, _ = polar(Z)\n",
    "    retracted_point = (X + xi) @ np.linalg.inv(U.T)\n",
    "    return retracted_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def riemannian_gradient_descent(X, Y, k, retraction_method, max_iter=100, lr=0.1, tol=1e-6):\n",
    "    n, p1 = X.shape\n",
    "    _, p2 = Y.shape\n",
    "    \n",
    "    A = np.random.randn(p1, k)\n",
    "    B = np.random.randn(p2, k)\n",
    "    A, _ = np.linalg.qr(A)\n",
    "    B, _ = np.linalg.qr(B)\n",
    "    \n",
    "    G_A = np.eye(p1)  # Metric for A\n",
    "    G_B = np.eye(p2)  # Metric for B\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    if np.isnan(A).any() or np.isnan(B).any() or np.isinf(A).any() or np.isinf(B).any():\n",
    "        print(\"Error: Metric matrices A and B must be positive definite.\")\n",
    "        return None\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        old_obj = cca_objective(X, Y, A, B)\n",
    "        grad_A, grad_B = cca_gradient(X, Y, A, B)\n",
    "        if np.isnan(grad_A).any() or np.isnan(grad_B).any():\n",
    "            print(\"Error: Gradient matrices grad_A and grad_B must not have NaN values.\")\n",
    "            return None\n",
    "        if np.isinf(grad_A).any() or np.isinf(grad_B).any():\n",
    "            print(\"Error: Gradient matrices grad_A and grad_B must not have Inf values.\")\n",
    "            return None\n",
    "\n",
    "        if retraction_method == 'cholesky':\n",
    "            A = cholesky_qr_retraction(A, G_A, -lr * grad_A)\n",
    "            B = cholesky_qr_retraction(B, G_B, -lr * grad_B)\n",
    "        elif retraction_method == 'polar':\n",
    "            A = polar_retraction(A, G_A, -lr * grad_A)\n",
    "            B = polar_retraction(B, G_B, -lr * grad_B)\n",
    "        \n",
    "        new_obj = cca_objective(X, Y, A, B)\n",
    "        if abs(new_obj - old_obj) < tol:\n",
    "            break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Compute canonical correlations\n",
    "    XA = X @ A\n",
    "    YB = Y @ B\n",
    "    correlations = np.diag(XA.T @ YB) / (n - 1)\n",
    "    \n",
    "    return A, B, correlations, end_time - start_time\n",
    "\n",
    "def run_experiment(X, Y, k_values, retraction_methods):\n",
    "    results = []\n",
    "    for k in k_values:\n",
    "        for method in retraction_methods:\n",
    "            A, B, correlations, runtime = riemannian_gradient_descent(X, Y, k, method)\n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'method': method,\n",
    "                'correlations': correlations,\n",
    "                'runtime': runtime\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = scaler.fit_transform(Y)\n",
    "\n",
    "# Run experiment\n",
    "k_values = [5, 10, 15, 20]\n",
    "retraction_methods = ['cholesky', 'polar']\n",
    "results = run_experiment(X, Y, k_values, retraction_methods)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cca_env_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
